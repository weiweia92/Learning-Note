{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本配置　　\n",
    "### 导入包和版本查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n",
      "10.1\n",
      "7603\n",
      "GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更新PyTorch\n",
    "\n",
    "`PyTorch`将被安装在`anaconda3/lib/python3.7/site-packages/torch/`目录下  \n",
    "`conda update pytorch torchvision -c pytorch`  \n",
    "\n",
    "### 固定随机种子\n",
    "\n",
    "`torch.manual_seed(0)`\n",
    "\n",
    "`torch.cuda.manual_seed_all(0)`  \n",
    "\n",
    "### 指定程序运行在特定GPU卡上\n",
    "\n",
    "在命令行指定环境变量\n",
    "\n",
    "`CUDA_VISIBLE_DEVICES=0,1 python train.py`\n",
    "或在代码中指定\n",
    "\n",
    "`os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'`   \n",
    "\n",
    "### 判断是否有CUDA支持\n",
    "\n",
    "`torch.cuda.is_available()`\n",
    "\n",
    "### 设置为cuDNN benchmark模式\n",
    "\n",
    "`Benchmark`模式会提升计算速度，但是由于计算中有随机性，每次网络前馈结果略有差异。\n",
    "\n",
    "`torch.backends.cudnn.benchmark = True`\n",
    "如果想要避免这种结果波动，设置\n",
    "\n",
    "`torch.backends.cudnn.deterministic = True`\n",
    "\n",
    "### 清除GPU存储\n",
    "\n",
    "有时`Control-C`中止运行后`GPU`存储没有及时释放，需要手动清空。在`PyTorch`内部可以\n",
    "\n",
    "`torch.cuda.empty_cache()`  \n",
    "或在命令行可以先使用`ps`找到程序的`PID`，再使用`kill`结束该进程\n",
    "\n",
    "`ps aux | grep python`   \n",
    "`ps aux:see every process on the system`  \n",
    "`kill -9 [pid]`\n",
    "或者直接重置没有被清空的`GPU`\n",
    "\n",
    "`nvidia-smi --gpu-reset -i [gpu_id]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量(Tensor)处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.Size([3, 4, 5])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(3,4,5)\n",
    "print(tensor.type())  # 数据类型\n",
    "print(tensor.size())  # 张量的shape，是个元组\n",
    "print(tensor.dim())   # 维度的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor[N, C, H, W]\n",
    "images = torch.randn(32, 3, 56, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 56, 56])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.sum(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428398394/work/c10/core/TensorImpl.h:806: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable.\n"
     ]
    }
   ],
   "source": [
    "NCHW = ['N', 'C', 'H', 'W']\n",
    "images = torch.randn(32, 3, 56, 56, names=NCHW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 56, 56])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.sum('C').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.6744e-01,  4.1752e-01,  2.8830e-01,  ..., -8.4218e-01,\n",
       "          -2.1659e-01, -9.8932e-01],\n",
       "         [ 1.1841e+00, -1.5200e+00, -1.2679e-02,  ..., -1.4709e+00,\n",
       "           2.9981e-01, -1.3500e+00],\n",
       "         [ 7.9807e-01,  1.0632e+00, -1.2566e+00,  ...,  6.1915e-01,\n",
       "          -1.3127e+00,  1.3306e-01],\n",
       "         ...,\n",
       "         [ 2.1473e+00, -8.3112e-01,  1.4068e+00,  ..., -7.4190e-01,\n",
       "           2.0996e+00, -1.2519e+00],\n",
       "         [-3.0205e-01,  3.9233e-03, -4.0610e-01,  ...,  4.1151e-01,\n",
       "           3.7060e-01,  1.5014e-01],\n",
       "         [ 1.3275e-01, -1.1107e+00,  1.2884e+00,  ...,  1.1835e-01,\n",
       "           1.3068e+00,  1.6116e-01]],\n",
       "\n",
       "        [[ 3.6937e-01,  2.1532e-01, -1.0256e+00,  ..., -2.1193e-01,\n",
       "           9.5672e-02,  1.5446e+00],\n",
       "         [ 5.0710e-01, -4.4327e-01,  4.4714e-01,  ..., -1.2731e+00,\n",
       "          -4.8913e-01,  8.1772e-01],\n",
       "         [-3.6150e-01,  7.9346e-01,  4.3908e-01,  ..., -1.7832e-01,\n",
       "          -3.3333e-01, -1.1776e+00],\n",
       "         ...,\n",
       "         [-8.9571e-01,  2.1155e+00,  1.9084e-02,  ...,  1.0032e+00,\n",
       "           6.7256e-01,  4.6426e-01],\n",
       "         [-1.1277e+00, -7.5367e-02, -3.6754e-02,  ..., -5.2815e-01,\n",
       "          -4.3337e-01, -1.4523e+00],\n",
       "         [ 6.0726e-02,  1.9997e+00, -3.7401e-01,  ...,  3.4325e-01,\n",
       "           5.4312e-01, -4.8730e-01]],\n",
       "\n",
       "        [[-1.0952e+00, -1.3036e+00,  3.3063e-01,  ..., -7.5227e-01,\n",
       "           7.6247e-01, -7.6985e-01],\n",
       "         [ 3.7081e-01, -3.4101e-01, -1.8533e+00,  ...,  1.7107e+00,\n",
       "           1.3564e+00, -2.9467e-01],\n",
       "         [-1.2604e+00, -3.2394e-02, -4.2860e-01,  ..., -7.6369e-01,\n",
       "          -2.1376e-02,  1.3429e+00],\n",
       "         ...,\n",
       "         [ 8.5770e-01,  1.7567e+00, -3.5681e-01,  ..., -1.2674e+00,\n",
       "           2.4379e-01, -2.7547e+00],\n",
       "         [ 3.9804e-01,  1.7703e-01,  4.3672e-01,  ...,  2.0730e+00,\n",
       "           6.1028e-01,  5.8297e-01],\n",
       "         [ 1.5312e+00, -5.9547e-01,  4.1028e-01,  ...,  4.8005e-01,\n",
       "           8.0279e-02,  8.7265e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 5.1553e-01, -1.7048e-02, -7.2547e-01,  ...,  1.5348e+00,\n",
       "           6.4391e-01, -1.8127e+00],\n",
       "         [-9.9997e-01,  6.5209e-01,  9.8783e-01,  ..., -4.5011e-01,\n",
       "           2.7668e-01,  2.4709e-01],\n",
       "         [-2.0606e+00, -5.9862e-02, -1.0984e+00,  ..., -1.1288e+00,\n",
       "           1.0580e+00,  2.6202e-02],\n",
       "         ...,\n",
       "         [-2.3742e-01,  2.2446e+00, -1.1487e-01,  ...,  1.4910e+00,\n",
       "          -2.1741e-02, -8.1595e-01],\n",
       "         [-1.0254e-02, -1.9362e+00, -1.1620e+00,  ..., -2.3521e-01,\n",
       "          -3.7648e-01, -1.0864e-01],\n",
       "         [ 6.1649e-01, -2.2608e-01, -3.2431e-01,  ...,  7.1727e-01,\n",
       "          -4.6916e-01,  1.6390e+00]],\n",
       "\n",
       "        [[ 8.1943e-01, -2.0197e+00,  2.2432e+00,  ..., -1.8487e-01,\n",
       "           7.7922e-01,  6.6248e-02],\n",
       "         [-9.7136e-01, -4.5828e-01,  8.2244e-01,  ...,  3.9421e+00,\n",
       "          -5.9814e-01, -3.0224e-01],\n",
       "         [ 7.8449e-01,  6.1549e-01,  3.8540e-01,  ...,  1.3037e+00,\n",
       "           7.3336e-01, -3.5654e-01],\n",
       "         ...,\n",
       "         [-1.4814e-01,  1.0789e+00, -4.4617e-01,  ...,  8.8753e-01,\n",
       "          -5.1112e-01,  1.2105e+00],\n",
       "         [ 1.1811e+00,  2.6669e-01, -3.5080e-01,  ..., -3.3841e-01,\n",
       "          -3.6590e+00, -1.3840e+00],\n",
       "         [-6.1897e-01, -1.9911e-02,  5.2520e-01,  ..., -2.6809e-01,\n",
       "           1.0025e-01,  2.7156e-01]],\n",
       "\n",
       "        [[ 7.6381e-01, -1.1866e+00,  2.1231e-01,  ...,  7.4042e-01,\n",
       "          -1.6110e+00, -2.3756e+00],\n",
       "         [ 3.5746e-03,  3.1918e-01,  8.7622e-01,  ..., -1.9978e-01,\n",
       "          -4.3805e-01, -3.6976e-01],\n",
       "         [-1.0227e-01, -9.0272e-01, -3.2976e-01,  ..., -1.6578e-01,\n",
       "          -1.0427e-01,  3.1180e-01],\n",
       "         ...,\n",
       "         [-1.3295e+00,  6.3419e-01, -6.1738e-01,  ...,  6.5884e-01,\n",
       "           7.8723e-02,  1.4568e+00],\n",
       "         [ 7.7213e-01, -6.1608e-01, -1.0237e+00,  ...,  5.7730e-01,\n",
       "           5.0959e-01, -8.4181e-02],\n",
       "         [-1.4792e-01,  7.6563e-01, -9.1248e-01,  ...,  1.7751e+00,\n",
       "          -1.2048e+00,  5.7987e-01]]], names=('N', 'H', 'W'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.select('C', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3,4,1,2,names=('C', 'N', 'H', 'W'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tensor.align_to('N', 'C', 'H', 'W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensor与np.ndarray转换\n",
    "除了CharTensor，其他所有CPU上的tensor都支持转换为numpy格式然后再转换回来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img_1 = np.random.randn(3,25,25)\n",
    "img_2 = torch.from_numpy(img_1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 25, 25)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.type>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_2.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_3 = img_2.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_3.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 25, 25)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.ndarray 与 PIL.Image的转换    \n",
    "`PyTorch`中的张量默认采用`N×D×H×W`的顺序，并且数据范围在[0, 1]，需要进行转置和规范化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,   0, 255,  ...,   0, 255,   0],\n",
       "         [  0, 242,   0,  ...,   0,   0,   0],\n",
       "         [255,   0,   0,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ..., 110,   0, 139],\n",
       "         [  0, 147,   0,  ..., 153,  15, 185],\n",
       "         [  0,  11,   0,  ...,   0, 146, 174]],\n",
       "\n",
       "        [[230,   0, 255,  ..., 140,   0, 255],\n",
       "         [  0, 177, 229,  ...,   0, 236,   0],\n",
       "         [  0, 255, 184,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,  57,  ..., 255,   0,  62],\n",
       "         [ 86,   0,   0,  ...,   0,   0, 213],\n",
       "         [255, 255,   0,  ...,   0,  78,   0]],\n",
       "\n",
       "        [[  0,   0,   0,  ...,  54,   0, 242],\n",
       "         [  0, 113, 114,  ..., 255, 154, 128],\n",
       "         [114,   0, 255,  ..., 244, 255,   0],\n",
       "         ...,\n",
       "         [ 87,   0,   0,  ...,   0,   0,  76],\n",
       "         [  0,   0,   0,  ...,   0,   0, 255],\n",
       "         [  0, 177,   0,  ...,  72, 255, 136]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.Tensor -> PIL.Image.  \n",
    "torch.clamp(img_2 * 255, min=0, max=255).byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.clamp(img_2 * 255, min=0, max=255).byte().permute(1, 2, 0).cpu().numpy() # permute：维度换位　\n",
    "#image = torchvision.transforms.functional.to_pil_image(img_2)  # Equivalently way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image -> torch.Tensor.\n",
    "tensor = torch.from_numpy(np.asarray(PIL.Image.open('/home/weiweia92/Downloads/kobe.jpeg'))).permute(2, 0, 1).float()/255\n",
    "#tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path))  # Equivalently way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.ndarray与PIL.Image转换\n",
    "\n",
    "`# np.ndarray -> PIL.Image.`\n",
    "`image = PIL.Image.fromarray(ndarray.astypde(np.uint8))`\n",
    "\n",
    "`# PIL.Image -> np.ndarray.`\n",
    "`ndarray = np.asarray(PIL.Image.open(path))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = torch.rand(1).item() # 提取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2026575207710266"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor 变形  \n",
    "在将卷积层输入全连接层的情况下通常需要对张量做形变处理，\n",
    "相比`torch.view，torch.reshape`可以自动处理输入张量不连续的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(2,3,4)\n",
    "shape = (6, 4)\n",
    "tensor = torch.reshape(tensor, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打乱顺序\n",
    "\n",
    "`tensor = tensor[torch.randperm(tensor.size(0))]  # Shuffle the first dimension`  \n",
    "\n",
    "### 水平翻转\n",
    "\n",
    "`PyTorch`不支持`tensor[::-1]`这样的负步长操作，水平翻转可以用张量索引实现。\n",
    "\n",
    "`# Assume tensor has shape N*D*H*W.`\n",
    "`tensor = tensor[:, :, :, torch.arange(tensor.size(3) - 1, -1, -1).long()]`  \n",
    "\n",
    "### 复制张量\n",
    "\n",
    "有三种复制的方式，对应不同的需求。   \n",
    "|`tensor.clone()`         |    `New/Shared memory      New `        | `Still in computation graph         Yes` |   \n",
    "|`tensor.detach()`        |    `New/Shared memory      Shared`      | `Still in computation graph          No` |  \n",
    "|`tensor.detach.clone()()`|    `New/Shared memory      New`         | `Still in computation graph          No` |  \n",
    "\n",
    "### 拼接张量\n",
    "\n",
    "注意`torch.cat`和`torch.stac`k的区别在于`torch.cat`沿着给定的维度拼接，而`torch.stack`会新增一维。例如当参数是3个10×5的张量，`torch.cat`的结果是30×5的张量，而`torch.stack`的结果是3×10×5的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.rand(10, 5)\n",
    "tensor2 = torch.rand(10, 5)\n",
    "tensor3 = torch.rand(10, 5)\n",
    "tensor_cat = torch.cat([tensor1, tensor2, tensor3], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 5])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 5])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_cat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.rand(10, 5)\n",
    "tensor2 = torch.rand(10, 5)\n",
    "tensor3 = torch.rand(10, 5)\n",
    "tensor_stack = torch.stack([tensor1, tensor2, tensor3], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 5])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0219, 0.6251],\n",
       "         [0.0798, 0.6325]],\n",
       "\n",
       "        [[0.9203, 0.3982],\n",
       "         [0.0589, 0.8266]],\n",
       "\n",
       "        [[0.8809, 0.1143],\n",
       "         [0.9980, 0.5072]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = tensor.size(0)\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 判断两个tensor相等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(tensor1, tensor2)  # float tensor\n",
    "torch.equal(tensor1, tensor2)     # int tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置默认类型，pytorch中的FloatTensor远远快于DoubleTensor\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 类型转换\n",
    "tensor = tensor.cuda()\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.cpu()\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.float()\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.long()\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "\n",
    "本质上来说，PyTorch 是一个处理张量的库。一个张量是一个数字、向量、矩阵或任何 n 维数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# number\n",
    "t1 = torch.tensor(4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector\n",
    "t2 = torch.tensor([1, 2, 3, 4])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix\n",
    "t3 = torch.tensor([[5., 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵乘法\n",
    "\n",
    "`# Matrix multiplication: (m*n) * (n*p) -> (m*p).`  \n",
    "`result = torch.mm(tensor1, tensor2)`  \n",
    "\n",
    "`# Batch matrix multiplication: (b*m*n) * (b*n*p) -> (b*m*p).`  \n",
    "`result = torch.bmm(tensor1, tensor2)`  \n",
    "\n",
    "`# Element-wise multiplication.`  \n",
    "`result = tensor1 * tensor2`  \n",
    "计算两组数据之间的两两欧式距离  \n",
    "\n",
    "`# X1 is of shape m*d, X2 is of shape n*d.`  \n",
    "`dist = torch.sqrt(torch.sum((X1[:,None,:] - X2) ** 2, dim=2))`   \n",
    "\n",
    "## 模型定义  \n",
    "\n",
    "### 卷积层\n",
    "\n",
    "最常用的卷积层配置是\n",
    "\n",
    "`conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True)`  \n",
    "`conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=True)`  \n",
    "\n",
    "### GAP（Global average pooling）层\n",
    "\n",
    "`gap = torch.nn.AdaptiveAvgPool2d(output_size=1)`  \n",
    "\n",
    "### 双线性汇合（bilinear pooling)  \n",
    "`\n",
    "X = torch.reshape(N, D, H * W)                        # Assume X has shape N*D*H*W\n",
    "X = torch.bmm(X, torch.transpose(X, 1, 2)) / (H * W)  # Bilinear pooling\n",
    "assert X.size() == (N, D, D)\n",
    "X = torch.reshape(X, (N, D * D))\n",
    "X = torch.sign(X) * torch.sqrt(torch.abs(X) + 1e-5)   # Signed-sqrt normalization\n",
    "X = torch.nn.functional.normalize(X)                  # L2 normalization`  \n",
    "\n",
    "### 多卡同步BN（Batch normalization）\n",
    "\n",
    "当使用`torch.nn.DataParallel`将代码运行在多张GPU卡上时，PyTorch的BN层默认操作是各卡上数据独立地计算均值和标准差，同步BN使用所有卡上的数据一起计算BN层的均值和标准差，缓解了当批量大小`（batch size）`比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的提升性能的技巧。\n",
    "\n",
    "现在PyTorch官方已经支持同步BN操作\n",
    "\n",
    "`sync_bn = torch.nn.SyncBatchNorm(num_features, eps=1e-05, momentum=0.1, affine=True, \n",
    "                                 track_running_stats=True)`  \n",
    "\n",
    "将已有网络的所有BN层改为同步BN层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-76-801794ad3fe5>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-76-801794ad3fe5>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    setattr(module, name) = convert_syncbn_model(child_module, process_group=process_group)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "def convertBNtoSyncBN(module, process_group=None):\n",
    "    '''Recursively replace all BN layers to SyncBN layer.\n",
    "\n",
    "    Args:\n",
    "        module[torch.nn.Module]. Network\n",
    "    '''\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        sync_bn = torch.nn.SyncBatchNorm(module.num_features, module.eps, module.momentum, \n",
    "                                         module.affine, module.track_running_stats, process_group)\n",
    "        sync_bn.running_mean = module.running_mean\n",
    "        sync_bn.running_var = module.running_var\n",
    "        if module.affine:\n",
    "            sync_bn.weight = module.weight.clone().detach()\n",
    "            sync_bn.bias = module.bias.clone().detach()\n",
    "        return sync_bn\n",
    "    else:\n",
    "        for name, child_module in module.named_children():\n",
    "            setattr(module, name) = convert_syncbn_model(child_module, process_group=process_group)\n",
    "        return module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算模型整体参数量\n",
    "\n",
    "\n",
    "`# torch.numel:返回输入张量中元素的总数   \n",
    "num_parameters = sum(torch.numel(parameter) for parameter in model.parameters())`  \n",
    "\n",
    "### 模型权值初始化\n",
    "\n",
    "注意`model.modules()`和`model.children()`的区别：`model.modules()`会迭代地遍历模型的所有子层，而`model.children()`只会返回模型最外层的子层\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# Common practise for initialization.\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_out',\n",
    "                                      nonlinearity='relu')\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.BatchNorm2d):\n",
    "        torch.nn.init.constant_(layer.weight, val=1.0)\n",
    "        torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(layer.weight)\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)`\n",
    "\n",
    "`# Initialization with given tensor.\n",
    "layer.weight = torch.nn.Parameter(tensor)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch其他注意事项\n",
    "\n",
    "### 模型定义\n",
    "\n",
    "建议有参数的层和汇合`（pooling）`层使用`torch.nn`模块定义，激活函数直接使用`torch.nn.functional`。`torch.nn`模块和`torch.nn.functional`的区别在于，`torch.nn`模块在计算时底层调用了`torch.nn.functional`，但`torch.nn`模块包括该层参数，还可以应对训练和测试两种网络状态。使用`torch.nn.functional`时要注意网络状态，如\n",
    "`def forward(self, x):\n",
    "    ...\n",
    "    x = torch.nn.functional.dropout(x, p=0.5, training=self.training)`\n",
    "`model(x)`前用`model.train()`和`model.eval()`切换网络状态。\n",
    "不需要计算梯度的代码块用`with torch.no_grad()`包含起来。`model.eval()`和`torch.no_grad()`的区别在于，`model.eval()`是将网络切换为测试状态，例如BN和dropout在训练和测试阶段使用不同的计算方法。`torch.no_grad()`是关闭`PyTorch`张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行`loss.backward()`。\n",
    "`torch.nn.CrossEntropyLoss`的输入不需要经过`Softmax`。`torch.nn.CrossEntropyLoss`等价于`torch.nn.functional.log_softmax + torch.nn.NLLLoss`。\n",
    "`loss.backward()`前用`optimizer.zero_grad()`清除累积梯度。`optimizer.zero_grad()`和`model.zero_grad()`效果一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
