{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本配置　　\n",
    "### 导入包和版本查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0+cu100\n",
      "10.0\n",
      "7603\n",
      "GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可复现性\n",
    "在硬件设备（CPU、GPU）不同时，完全的可复现性无法保证，即使随机种子相同。但是，在同一个设备上，应该保证可复现性。具体做法是，在程序开始的时候固定torch的随机种子，同时也把numpy的随机种子固定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显卡设置\n",
    "如果只需要一张显卡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要指定多张显卡，比如0，1号显卡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以在命令行运行代码时设置显卡：  \n",
    "`CUDA_VISIBLE_DEVICES=0,1 python train.py`  \n",
    "清除缓存　　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量(Tensor)处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.Size([3, 4, 5])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(3,4,5)\n",
    "print(tensor.type())  # 数据类型\n",
    "print(tensor.size())  # 张量的shape，是个元组\n",
    "print(tensor.dim())   # 维度的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor[N, C, H, W]\n",
    "images = torch.randn(32, 3, 56, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 56, 56])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.sum(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/c10/core/TensorImpl.h:845: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable.\n"
     ]
    }
   ],
   "source": [
    "NCHW = ['N', 'C', 'H', 'W']\n",
    "images = torch.randn(32, 3, 56, 56, names=NCHW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 56, 56])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.sum('C').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-9.9507e-01,  4.5089e-01,  1.4671e-01,  ...,  3.4687e-01,\n",
       "          -2.9055e-01, -1.7921e+00],\n",
       "         [-5.8186e-01, -2.5670e-01,  7.5862e-01,  ..., -3.1995e-02,\n",
       "          -4.1721e-01, -7.8874e-01],\n",
       "         [ 1.1152e+00, -1.1732e+00,  1.7059e-01,  ...,  9.0192e-01,\n",
       "           9.1724e-01,  8.2328e-01],\n",
       "         ...,\n",
       "         [ 1.2963e+00, -9.4490e-01,  5.7915e-01,  ..., -8.5010e-01,\n",
       "          -1.0993e+00,  8.6259e-01],\n",
       "         [-2.2042e-01,  3.9036e-01, -9.8582e-02,  ..., -1.8150e-01,\n",
       "           9.1908e-02,  4.3104e-02],\n",
       "         [ 1.9219e+00,  2.1617e+00, -6.1160e-01,  ...,  1.5528e-01,\n",
       "          -1.9943e+00, -1.0316e+00]],\n",
       "\n",
       "        [[-2.3882e+00,  1.0923e+00,  6.3999e-01,  ..., -9.5147e-01,\n",
       "           4.0850e-02,  2.7926e-01],\n",
       "         [-7.1295e-01,  1.1391e-01,  5.9903e-01,  ...,  1.7090e-01,\n",
       "           5.9664e-01, -3.2352e-01],\n",
       "         [-1.7379e+00, -1.2598e+00,  2.7185e-01,  ..., -1.0333e+00,\n",
       "          -2.4391e-01, -2.1693e-01],\n",
       "         ...,\n",
       "         [ 8.2945e-01, -1.7793e+00,  9.3147e-01,  ...,  2.0978e-01,\n",
       "          -3.2148e+00, -3.1787e-01],\n",
       "         [ 1.4117e-01, -8.1717e-01,  1.1234e+00,  ...,  9.9212e-01,\n",
       "           1.8956e+00,  2.9508e-01],\n",
       "         [ 1.9193e-01, -5.9670e-01,  3.4295e-01,  ..., -1.2804e+00,\n",
       "          -1.7449e+00,  7.1708e-01]],\n",
       "\n",
       "        [[ 7.1379e-01, -6.6333e-01,  1.0524e+00,  ...,  2.0533e+00,\n",
       "          -7.9627e-01, -9.9690e-01],\n",
       "         [ 2.7529e-01, -1.4219e+00, -6.2855e-01,  ..., -1.3472e+00,\n",
       "           8.2672e-02,  5.3864e-01],\n",
       "         [-3.5758e-01, -2.1023e-01, -2.0285e+00,  ...,  3.4313e-01,\n",
       "           7.0022e-01,  1.6138e+00],\n",
       "         ...,\n",
       "         [ 2.5099e-01, -1.4003e+00,  6.5376e-01,  ...,  4.4966e-01,\n",
       "           3.2110e-01,  4.2598e-01],\n",
       "         [-8.9031e-01,  1.0223e+00, -1.8973e+00,  ..., -1.1942e+00,\n",
       "          -1.3702e+00, -1.1444e+00],\n",
       "         [ 4.2370e-01,  6.9348e-01,  4.4718e-02,  ..., -1.2818e+00,\n",
       "           2.8415e-01,  1.2318e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.0113e+00, -5.9237e-02,  1.2974e-01,  ..., -5.0613e-01,\n",
       "          -9.9826e-01, -8.6872e-01],\n",
       "         [ 1.4320e+00,  2.2420e+00, -8.3892e-02,  ...,  4.8049e-01,\n",
       "          -1.2147e-02, -1.5252e+00],\n",
       "         [ 1.2196e-01,  9.1906e-01,  1.2272e-03,  ..., -9.8205e-02,\n",
       "           2.7062e-01, -7.1028e-01],\n",
       "         ...,\n",
       "         [-2.4992e-01, -1.3572e-01, -3.8305e-01,  ..., -6.7034e-01,\n",
       "           7.6584e-01,  1.8899e-01],\n",
       "         [ 1.4041e+00,  2.7856e-01,  1.3397e+00,  ..., -2.3389e-01,\n",
       "          -7.8920e-02,  9.1205e-01],\n",
       "         [-1.8350e-01,  8.1860e-01, -9.8711e-02,  ...,  1.2246e+00,\n",
       "           1.5626e+00,  1.6686e+00]],\n",
       "\n",
       "        [[ 4.6437e-01, -1.8114e+00, -6.4023e-01,  ...,  8.7829e-02,\n",
       "          -6.3912e-01,  4.9878e-01],\n",
       "         [-1.1809e+00, -3.8909e-01, -1.0589e+00,  ..., -4.0348e-02,\n",
       "          -1.0239e+00, -7.1563e-01],\n",
       "         [ 1.1865e+00, -4.8292e-01, -6.7639e-01,  ...,  2.5219e-01,\n",
       "          -9.2468e-01, -2.0877e-01],\n",
       "         ...,\n",
       "         [ 8.7024e-01,  2.3480e-01,  4.5666e-01,  ...,  5.7742e-01,\n",
       "          -6.8937e-01,  1.0730e+00],\n",
       "         [ 1.4065e-01,  4.5920e-01, -3.5110e-01,  ...,  9.5624e-02,\n",
       "          -2.3467e+00,  2.4157e-01],\n",
       "         [-1.1767e+00,  4.5980e-01,  4.1333e-01,  ..., -4.6395e-01,\n",
       "          -6.9644e-01,  6.6585e-01]],\n",
       "\n",
       "        [[-2.4263e-01, -7.9807e-01,  5.5958e-01,  ..., -7.2828e-01,\n",
       "           1.2800e+00, -2.1905e-01],\n",
       "         [-3.1086e-01,  7.4047e-01,  9.6573e-01,  ..., -5.0713e-01,\n",
       "           7.0260e-01, -8.5787e-01],\n",
       "         [ 2.7317e+00,  1.0906e-01, -8.9132e-02,  ...,  7.8927e-01,\n",
       "          -4.0125e-01, -1.4858e+00],\n",
       "         ...,\n",
       "         [-2.4502e-01, -1.3706e-01,  1.3190e-01,  ..., -5.1494e-02,\n",
       "           8.2147e-01, -3.8204e-01],\n",
       "         [-7.7325e-01,  7.7371e-01,  2.9647e-01,  ..., -1.2004e+00,\n",
       "          -1.1874e+00,  2.1483e+00],\n",
       "         [-1.9807e+00, -1.5700e+00,  8.7842e-01,  ..., -1.8496e+00,\n",
       "           7.3980e-01, -1.4966e-01]]], names=('N', 'H', 'W'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.select('C', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3,4,1,2,names=('C', 'N', 'H', 'W'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tensor.align_to('N', 'C', 'H', 'W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensor与np.ndarray转换\n",
    "除了CharTensor，其他所有CPU上的tensor都支持转换为numpy格式然后再转换回来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = np.random.randn(3,25,25)\n",
    "img_2 = torch.from_numpy(img).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 25, 25)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.type>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_2.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_3 = img_2.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_3.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 25, 25)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.ndarray 与 PIL.Image的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0, 253, ...,   0,   0,   0],\n",
       "        [  0,   1,   0, ...,   0, 255,   1],\n",
       "        [  0,   0, 255, ...,   1,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   1,   2, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0, 255]],\n",
       "\n",
       "       [[  1,   0, 255, ..., 254,   0,   1],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   1, ..., 255,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   1,   0],\n",
       "        [  1,   0,   1, ...,   0,   1,   0],\n",
       "        [  1, 255,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       [[  0,   0, 255, ..., 254, 254,   0],\n",
       "        [  1,   0,   0, ...,   0,   0,   0],\n",
       "        [  0, 255,   1, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   1,   1, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0, 255,   0],\n",
       "        [  0,   0,   1, ...,   0,   0, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_3.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 25), |u1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 25), '|u1')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-522c287b98fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 25), |u1"
     ]
    }
   ],
   "source": [
    "image = PIL.Image.fromarray(img_3.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndarray = np.asarray(PIL.Image.open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = torch.rand(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置默认类型，pytorch中的FloatTensor远远快于DoubleTensor\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 类型转换\n",
    "tensor = tensor.cuda()\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.cpu()\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.float()\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.long()\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "\n",
    "本质上来说，PyTorch 是一个处理张量的库。一个张量是一个数字、向量、矩阵或任何 n 维数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# number\n",
    "t1 = torch.tensor(4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector\n",
    "t2 = torch.tensor([1, 2, 3, 4])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix\n",
    "t3 = torch.tensor([[5., 6]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
