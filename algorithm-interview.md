## 算法工程师面试

### 深度学习 

#### 模型评估方法

- Accuracy作为指标有哪些局限性？

当正负样本极度不均衡时存在问题！比如，正样本有99%时，分类器只要将所有样本划分为正样本就可以达到99%的准确率。但显然这个分类器是存在问题的。当正负样本不均衡时，常用的评价指标为ROC曲线和PR曲线。

- ROC曲线和PR曲线各是什么？

ROC:由FPR(False positive rate)和TPR(True positive rate)为横纵坐标的曲线  

FPR:FP/(FP+TN)误分为正样本的负样本占所有实际负样本的比例  

TPR:TP/(TP+FN)正确分类的正样本占所有实际正样本的比例  

True Positive, TP: 正确的正样本(预测为正样本，实际也为正样本)

False Positive, FP:错误的正样本(预测为正样本，实际为负样本)

True Negative, TN: 正确的负样本(预测为负样本，实际也为负样本)

False Negative, FN: 错误的负样本(预测为负样本，实际为正样本)

PR:Precision-Recall曲线，x:Recall，y:Precision  

Precision=TP/(TP+FP), 正确的正样本占所有预测正样本的比例

Recall=TP/(TP+FN)， 正确的正样本占所有实际正样本的比例

ROC越靠左上角效果越好，AUC为横纵坐标围成的面积，越大越好.  

- F1 Score

F1=2\*precision\*recall/(precision+recall)  

- 编程实现AUC的计算，并指出复杂度？

- AUC指标有什么特点？放缩结果对AUC是否有影响？

- 余弦距离与欧式距离有什么特点？

### 基本方法

- 如何划分训练集？如何选取验证集？
- 什么是偏差和方差？

- 什么是过拟合？深度学习解决过拟合的方法有哪

- 解决欠拟合的方法有哪些？

- 深度模型参数调整的一般方法论？

### 优化方法

- 简述了解的优化器，发展综述？


- 常用的损失函数有哪些？分别适用于什么场景？


- 梯度下降与拟牛顿法的异同？

- L1和L2正则分别有什么特点？为何L1稀疏？

### 深度学习基础

- 以一层隐层的神经网络，relu激活，MSE作为损失函数推导反向传播

- NN的权重参数能否初始化为0？

- 常用的激活函数，导数？

- relu的有优点？又有什么局限性？他们的系列改进方法是啥？

- sigmoid和tanh为什么会导致梯度消失？

- 一个隐层需要多少节点能实现包含n元输入的任意布尔函数？

- 多个隐层实现包含n元输入的任意布尔函数，需要多少节点和网络层？

- dropout为何能防止过拟合？

- dropout和BN 在前向传播和方向传播阶段的区别？

### CNN

- 给定卷积核的尺寸，特征图大小计算方法？


- 网络容量计算方法

- 共享参数有什么优点

- 常用的池化操作有哪些？有什么特点？

- CNN如何用于文本分类？

- resnet提出的背景和核心理论是？

- 空洞卷积是什么？有什么应用场景？

### RNN

- 简述RNN，LSTM，GRU的区别和联系

- 画出lstm的结构图，写出公式

- RNN的梯度消失问题？如何解决？

- lstm中是否可以用relu作为激活函数？

- lstm各个门分别使用什么激活函数？

- 简述seq2seq模型？

- seq2seq在解码时候有哪些方法？

- Attention机制是什么？



## 机器学习

### 基础

- 样本不均衡如何处理？
- 什么是生成模型什么是判别模型？

### 集成学习

- 集成学习的分类？有什么代表性的模型和方法？
- 如何从偏差和方差的角度解释bagging和boosting的原理？
- GBDT的原理？和Xgboost的区别联系？
- adaboost和gbdt的区别联系？

### 模型 

- 手推LR、Kmeans、SVM
- 简述ridge和lasson的区别和联系
- 树模型如何调参
- 树模型如何剪枝？
- 是否存一定存在参数，使得SVM的训练误差能到0
- 逻辑回归如何处理多分类？
- 决策树有哪些划分指标？区别与联系？
- 简述SVD和PCA的区别和联系？
- 如何使用梯度下降方法进行矩阵分解？
- LDA与PCA的区别与联系？

### 特征工程 

- 常用的特征筛选方法有哪些？
- 文本如何构造特征？
- 类别变量如何构造特征？
- 连续值变量如何构造特征？
- 哪些模型需要对特征进行归一化？
- 什么是组合特征？如何处理高维组合特征？
